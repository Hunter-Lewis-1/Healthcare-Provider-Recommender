{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare Provider Recommendation System Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis and visualization of the Healthcare Provider Recommendation System, demonstrating the effectiveness of collaborative filtering, clustering, and Pareto optimization for personalized healthcare provider recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize imports by only importing necessary components\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set optimized plot settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "# Use vectorized operations by default\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data\n",
    "\n",
    "We begin by loading the synthetic provider and rating data, then performing preliminary exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data efficiently with optimized read operations\n",
    "data_dir = Path('../data')\n",
    "\n",
    "# Check if data exists, generate if not\n",
    "if not (data_dir / 'providers_data.csv').exists() or not (data_dir / 'ratings_data.csv').exists():\n",
    "    print(\"Generating synthetic data...\")\n",
    "    from generate import generate_provider_data, save_data\n",
    "    providers_df, ratings_df = generate_provider_data()\n",
    "    save_data(providers_df, ratings_df)\n",
    "    print(f\"Generated {len(providers_df)} providers and {len(ratings_df)} ratings\")\n",
    "else:\n",
    "    # Use optimized CSV reading with appropriate dtypes\n",
    "    providers_df = pd.read_csv(data_dir / 'providers_data.csv', \n",
    "                              dtype={'provider_id': np.int32, 'quality_score': np.float32,\n",
    "                                     'cost': np.float32, 'specialty': 'category',\n",
    "                                     'latitude': np.float32, 'longitude': np.float32})\n",
    "    \n",
    "    ratings_df = pd.read_csv(data_dir / 'ratings_data.csv',\n",
    "                            dtype={'patient_id': np.int32, 'provider_id': np.int32,\n",
    "                                   'rating': np.float32})\n",
    "    \n",
    "    print(f\"Loaded {len(providers_df)} providers and {len(ratings_df)} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiently display summary information\n",
    "print(\"Providers Dataset - First 5 rows:\")\n",
    "display(providers_df.head())\n",
    "\n",
    "print(\"\\nRatings Dataset - First 5 rows:\")\n",
    "display(ratings_df.head())\n",
    "\n",
    "# Use vectorized operations for data profiling\n",
    "providers_stats = pd.DataFrame({\n",
    "    'Count': providers_df.count(),\n",
    "    'Missing': providers_df.isna().sum(),\n",
    "    'Mean': providers_df.select_dtypes(include=[np.number]).mean(),\n",
    "    'Std': providers_df.select_dtypes(include=[np.number]).std(),\n",
    "    'Min': providers_df.select_dtypes(include=[np.number]).min(),\n",
    "    'Max': providers_df.select_dtypes(include=[np.number]).max()\n",
    "})\n",
    "\n",
    "print(\"\\nProviders Dataset Statistics:\")\n",
    "display(providers_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis\n",
    "\n",
    "Analysis of key data characteristics and relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specialty distribution using vectorized operations\n",
    "plt.figure(figsize=(10, 6))\n",
    "specialty_counts = providers_df['specialty'].value_counts()\n",
    "ax = specialty_counts.plot(kind='bar', color=sns.color_palette(\"viridis\", len(specialty_counts)))\n",
    "plt.title('Distribution of Provider Specialties')\n",
    "plt.xlabel('Specialty')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Optimize bar annotations\n",
    "for i, v in enumerate(specialty_counts):\n",
    "    ax.text(i, v + 30, f\"{v:,}\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze rating distribution with optimized KDE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(ratings_df['rating'], bins=20, kde=True, stat=\"density\")\n",
    "plt.title('Distribution of Patient Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate rating statistics using optimized vectorized operations\n",
    "rating_stats = {\n",
    "    'Mean Rating': ratings_df['rating'].mean(),\n",
    "    'Median Rating': ratings_df['rating'].median(),\n",
    "    'Rating STD': ratings_df['rating'].std(),\n",
    "    'Min Rating': ratings_df['rating'].min(),\n",
    "    'Max Rating': ratings_df['rating'].max(),\n",
    "    'Rating Count': len(ratings_df)\n",
    "}\n",
    "\n",
    "print(\"Rating Statistics:\")\n",
    "display(pd.Series(rating_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize quality-cost relationship\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Use efficient hex binning for large datasets\n",
    "hb = plt.hexbin(providers_df['quality_score'], providers_df['cost'], \n",
    "                gridsize=30, cmap='viridis', mincnt=1)\n",
    "cb = plt.colorbar(hb, label='Provider Count')\n",
    "\n",
    "plt.title('Relationship Between Provider Quality and Cost')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "# Calculate correlation efficiently\n",
    "corr, p_val = pearsonr(providers_df['quality_score'], providers_df['cost'])\n",
    "plt.annotate(f'Correlation: {corr:.2f}\\nP-value: {p_val:.4f}', \n",
    "             xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spatial distribution of providers with optimized scatter plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Use specialized colormap for better visualization\n",
    "scatter = plt.scatter(providers_df['longitude'], providers_df['latitude'],\n",
    "                     c=providers_df['quality_score'], cmap='viridis', \n",
    "                     alpha=0.7, s=20, edgecolor='none')\n",
    "\n",
    "# Add color bar for quality score\n",
    "plt.colorbar(scatter, label='Quality Score')\n",
    "plt.title('Geographic Distribution of Providers (Color = Quality Score)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering Analysis\n",
    "\n",
    "Implementing K-means clustering to group similar providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import optimized clustering functions\n",
    "from clustering import cluster_providers, get_cluster_stats\n",
    "\n",
    "# Create normalized features efficiently using vectorized operations\n",
    "providers_df['quality_norm'] = (providers_df['quality_score'] - providers_df['quality_score'].min()) / \\\n",
    "                             (providers_df['quality_score'].max() - providers_df['quality_score'].min())\n",
    "providers_df['cost_norm'] = (providers_df['cost'] - providers_df['cost'].min()) / \\\n",
    "                          (providers_df['cost'].max() - providers_df['cost'].min())\n",
    "\n",
    "# Measure clustering time\n",
    "start_time = time()\n",
    "\n",
    "# Apply clustering with efficient implementation\n",
    "n_clusters = 5\n",
    "labels = cluster_providers(providers_df, n_clusters)\n",
    "\n",
    "# Get cluster statistics\n",
    "cluster_stats = get_cluster_stats(providers_df)\n",
    "\n",
    "end_time = time()\n",
    "print(f\"Clustering completed in {end_time - start_time:.4f} seconds\")\n",
    "print(\"\\nCluster Statistics:\")\n",
    "display(cluster_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters with optimized plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Use tab10 colormap for distinct cluster colors\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "# Plot clusters efficiently using fewer iterations\n",
    "for i in range(n_clusters):\n",
    "    mask = providers_df['cluster'] == i\n",
    "    plt.scatter(\n",
    "        providers_df.loc[mask, 'quality_score'],\n",
    "        providers_df.loc[mask, 'cost'],\n",
    "        color=colors[i],\n",
    "        alpha=0.5,\n",
    "        s=30,\n",
    "        label=f'Cluster {i} (n={mask.sum():,})'\n",
    "    )\n",
    "\n",
    "# Add cluster centroids\n",
    "for i, stats in cluster_stats.iterrows():\n",
    "    plt.scatter(\n",
    "        stats['quality_mean'],\n",
    "        stats['cost_mean'],\n",
    "        s=200,\n",
    "        color=colors[i],\n",
    "        marker='X',\n",
    "        edgecolor='black',\n",
    "        linewidth=1.5\n",
    "    )\n",
    "\n",
    "plt.title('Provider Clusters: Quality vs Cost')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D visualization of clusters for better insights\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Efficiently plot clusters in 3D\n",
    "for i in range(n_clusters):\n",
    "    mask = providers_df['cluster'] == i\n",
    "    ax.scatter(\n",
    "        providers_df.loc[mask, 'quality_score'],\n",
    "        providers_df.loc[mask, 'cost'],\n",
    "        providers_df.loc[mask, 'latitude'],  # Use latitude as third dimension\n",
    "        color=colors[i],\n",
    "        alpha=0.5,\n",
    "        s=20,\n",
    "        label=f'Cluster {i}'\n",
    "    )\n",
    "\n",
    "ax.set_title('3D Visualization of Provider Clusters')\n",
    "ax.set_xlabel('Quality Score')\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_zlabel('Latitude')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative Filtering Analysis\n",
    "\n",
    "Creating a user-item matrix and applying SVD for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collaborative_filtering import collaborative_filter\n",
    "\n",
    "# Create user-item matrix efficiently\n",
    "print(\"Creating user-item matrix...\")\n",
    "start_time = time()\n",
    "\n",
    "# Use pivot for sparse data representation\n",
    "ratings_matrix = ratings_df.pivot(\n",
    "    index='patient_id',\n",
    "    columns='provider_id',\n",
    "    values='rating'\n",
    ").fillna(0)\n",
    "\n",
    "end_time = time()\n",
    "print(f\"User-item matrix created in {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Matrix shape: {ratings_matrix.shape}\")\n",
    "print(f\"Density: {ratings_df.shape[0] / (ratings_matrix.shape[0] * ratings_matrix.shape[1]):.4%}\")\n",
    "\n",
    "# Apply SVD for collaborative filtering\n",
    "print(\"\\nApplying SVD for collaborative filtering...\")\n",
    "start_time = time()\n",
    "\n",
    "# Use optimized SVD implementation\n",
    "k = 50  # Number of latent factors\n",
    "U, sigma, Vt = collaborative_filter(ratings_matrix, k=k)\n",
    "\n",
    "end_time = time()\n",
    "print(f\"SVD completed in {end_time - start_time:.4f} seconds\")\n",
    "print(f\"U shape: {U.shape}, sigma shape: {sigma.shape}, Vt shape: {Vt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize singular values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(sigma) + 1), sigma, 'o-', linewidth=2)\n",
    "plt.title('Singular Values Distribution')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Singular Value')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "total_variance = np.sum(sigma**2)\n",
    "cumulative_variance = np.cumsum(sigma**2) / total_variance\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(sigma) + 1), cumulative_variance, 'o-', linewidth=2)\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Explained Variance')\n",
    "\n",
    "# Find minimum k for 90% variance\n",
    "k_90 = np.argmax(cumulative_variance >= 0.9) + 1\n",
    "plt.axvline(x=k_90, color='g', linestyle='--', label=f'k={k_90} (90% Variance)')\n",
    "\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommendation Analysis\n",
    "\n",
    "Generating and analyzing recommendations for specific patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommender import HealthcareRecommender\n",
    "\n",
    "# Initialize the recommender system\n",
    "print(\"Initializing recommender system...\")\n",
    "start_time = time()\n",
    "recommender = HealthcareRecommender(data_dir='data')\n",
    "end_time = time()\n",
    "print(f\"Recommender initialized in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Get sample patient IDs\n",
    "sample_patient_ids = ratings_df['patient_id'].value_counts().head(3).index.tolist()\n",
    "print(f\"Sample patient IDs with most ratings: {sample_patient_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "patient_id = sample_patient_ids[0]  # Take first sample patient\n",
    "top_n = 10\n",
    "\n",
    "print(f\"Generating {top_n} recommendations for patient {patient_id}...\")\n",
    "start_time = time()\n",
    "recommendations = recommender.recommend(patient_id, top_n=top_n)\n",
    "end_time = time()\n",
    "print(f\"Recommendations generated in {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Display recommendations\n",
    "print(\"\\nTop recommended healthcare providers:\")\n",
    "display(recommendations[['provider_id', 'quality_score', 'cost', 'specialty', 'predicted_rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recommendations on the quality-cost plane\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot all providers using alpha for better visualization\n",
    "plt.scatter(\n",
    "    recommender.providers_df['quality_score'], \n",
    "    recommender.providers_df['cost'],\n",
    "    alpha=0.15, \n",
    "    s=20,\n",
    "    color='gray',\n",
    "    label='All Providers'\n",
    ")\n",
    "\n",
    "# Plot providers the patient has rated\n",
    "rated_providers = ratings_df[ratings_df['patient_id'] == patient_id]\n",
    "rated_provider_ids = rated_providers['provider_id'].values\n",
    "rated_providers_df = recommender.providers_df[recommender.providers_df['provider_id'].isin(rated_provider_ids)]\n",
    "\n",
    "plt.scatter(\n",
    "    rated_providers_df['quality_score'],\n",
    "    rated_providers_df['cost'],\n",
    "    color='blue',\n",
    "    alpha=0.7,\n",
    "    s=60,\n",
    "    label=f'Previously Rated ({len(rated_providers_df)} providers)'\n",
    ")\n",
    "\n",
    "# Highlight recommended providers\n",
    "plt.scatter(\n",
    "    recommendations['quality_score'],\n",
    "    recommendations['cost'],\n",
    "    color='red',\n",
    "    s=120,\n",
    "    marker='*',\n",
    "    label=f'Recommendations (top {top_n})'\n",
    ")\n",
    "\n",
    "plt.title(f'Provider Recommendations for Patient {patient_id} on Quality-Cost Plane')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze recommendation specialty distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Get specialty distributions\n",
    "all_specialty_dist = providers_df['specialty'].value_counts(normalize=True)\n",
    "rated_specialty_dist = rated_providers_df['specialty'].value_counts(normalize=True) \n",
    "rec_specialty_dist = recommendations['specialty'].value_counts(normalize=True)\n",
    "\n",
    "# Combine into one DataFrame for comparison\n",
    "specialty_comparison = pd.DataFrame({\n",
    "    'All Providers': all_specialty_dist,\n",
    "    'Patient Rated': rated_specialty_dist.reindex(all_specialty_dist.index, fill_value=0),\n",
    "    'Recommendations': rec_specialty_dist.reindex(all_specialty_dist.index, fill_value=0)\n",
    "})\n",
    "\n",
    "# Plot as grouped bar chart\n",
    "specialty_comparison.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title(f'Specialty Distribution Comparison for Patient {patient_id}')\n",
    "plt.xlabel('Specialty')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pareto Optimization Analysis\n",
    "\n",
    "Analyzing how Pareto optimization balances quality, cost, and predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimize_pareto import fast_non_dominated_sort\n",
    "\n",
    "# Get all provider data with predicted ratings for this patient\n",
    "from collaborative_filtering import predict_ratings\n",
    "\n",
    "# Get predicted ratings for the current patient\n",
    "predicted_ratings = predict_ratings(\n",
    "    recommender.U, \n",
    "    recommender.sigma, \n",
    "    recommender.Vt, \n",
    "    patient_id, \n",
    "    recommender.ratings_matrix\n",
    ")\n",
    "\n",
    "# Create dataframe with objectives\n",
    "objectives = recommender.providers_df[['provider_id', 'quality_norm', 'cost_norm']].copy()\n",
    "objectives['rating_pred'] = predicted_ratings\n",
    "objectives['cost_norm'] = -objectives['cost_norm']  # Negate for maximization\n",
    "\n",
    "# Get Pareto front\n",
    "front_indices = fast_non_dominated_sort(objectives)\n",
    "pareto_front = objectives.iloc[front_indices].copy()\n",
    "\n",
    "print(f\"Found {len(pareto_front)} solutions on the Pareto front\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Pareto front\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot all solutions with transparency\n",
    "ax.scatter(\n",
    "    objectives['quality_norm'],\n",
    "    -objectives['cost_norm'],  # Revert the negation for visualization\n",
    "    objectives['rating_pred'],\n",
    "    alpha=0.1,\n",
    "    s=20,\n",
    "    color='gray',\n",
    "    label='All Providers'\n",
    ")\n",
    "\n",
    "# Plot Pareto front\n",
    "ax.scatter(\n",
    "    pareto_front['quality_norm'],\n",
    "    -pareto_front['cost_norm'],  # Revert the negation for visualization\n",
    "    pareto_front['rating_pred'],\n",
    "    alpha=1.0,\n",
    "    s=60,\n",
    "    color='blue',\n",
    "    label='Pareto Front'\n",
    ")\n",
    "\n",
    "# Plot top recommendations\n",
    "top_recommendations = objectives[objectives['provider_id'].isin(recommendations['provider_id'])]\n",
    "ax.scatter(\n",
    "    top_recommendations['quality_norm'],\n",
    "    -top_recommendations['cost_norm'],  # Revert the negation for visualization\n",
    "    top_recommendations['rating_pred'],\n",
    "    alpha=1.0,\n",
    "    s=120,\n",
    "    color='red',\n",
    "    marker='*',\n",
    "    label='Recommendations'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Quality (normalized)')\n",
    "ax.set_ylabel('Cost (normalized)')\n",
    "ax.set_zlabel('Predicted Rating')\n",
    "ax.set_title('3D Visualization of Pareto Front and Recommendations')\n",
    "ax.legend()\n",
    "\n",
    "# Rotate for better view\n",
    "ax.view_init(el
